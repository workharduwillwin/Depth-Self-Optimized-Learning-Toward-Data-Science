# Depth-Self-Optimized-Learning-Toward-Data-Science
We proposed a two-stage model called Depth Self-Optimized Learning(DSOL). DSOL is used to realize ANN depth self-configuration, self-optimization. 
# Background
A large number of studies have shown that the performance of ANN is closely related to its depth and width. Although it's possible to develop a universal model based on some theorm such as universal approximation theorem so that could approximate on various datasets, according to the no free lunch(NFL) theorem, no model could fit all kinds of datasets. Even if we design a general model for a variety of different datasets within the allowable error range, we do not need to use more complex methods for those tasks can be completed by simple methods. However, If a model could optimized itself according to specific datasets, maybe it can be adapted to a variety of different datasets. Based on those ideas mentioned above, we decide to develop a model could realize ANN depth self-optimized, self-configuration so as to be able to approximate on more different kinds of datasets.
# File
## List
> "Depth self-optimized learning toward datascience  "
>>"F-model(First-stage of DSOL) test"
>>>"F-model test.ipynb"
>>>>Figures created by "F-model test.ipynb"  
>>"RL-stage(Second-stage of DSOL)&DSOL test"
>>>"second stage of Depth self-optimized learning test& total framework valid"
>>>>Figures created by "second stage of Depth self-optimized learning test& total framework valid" & create figure.ipynb
>>>>Data created by "second stage of Depth self-optimized learning test& total framework valid"
>>>>Weights of RL-stage
 
